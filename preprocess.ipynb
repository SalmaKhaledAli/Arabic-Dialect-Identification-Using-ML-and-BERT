{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://cdn.discordapp.com/attachments/778630432878362676/934217772664258560/MultiTest.rar\n",
        "!wget https://cdn.discordapp.com/attachments/778630432878362676/934217856114122752/MultiDev.rar\n",
        "!wget https://cdn.discordapp.com/attachments/778630432878362676/934217865811349504/MultiTrain.Shuffled.rar"
      ],
      "metadata": {
        "id": "GNGY9U8BZfxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "xo0u5gb0Zkl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x \"/content/MultiDev.rar\" \"/content/Data/\"\n",
        "!unrar x \"/content/MultiTest.rar\" \"/content/Data/\"\n",
        "!unrar x \"/content/MultiTrain.Shuffled.rar\" \"/content/Data/\""
      ],
      "metadata": {
        "id": "LkpI95TWZhw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxmRSKv9ZCEO"
      },
      "outputs": [],
      "source": [
        "Corpus=\"/content/Data/MultiTrain.Shuffled.csv\"\n",
        "Devset=\"/content/Data/MultiDev.csv\"\n",
        "Testset=\"/content/Data/MultiTest.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(Corpus)\n",
        "df_dev = pd.read_csv(Devset)\n",
        "df_test = pd.read_csv(Testset)"
      ],
      "metadata": {
        "id": "QRAdoDGOZDcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.dropna(inplace=True)\n",
        "df_dev.dropna(inplace=True)\n",
        "df_test.dropna(inplace=True)\n",
        "\n",
        "df_train.drop_duplicates(subset=['text'] , keep=\"first\",inplace=True)\n",
        "df_dev.drop_duplicates(subset=['text'] , keep=\"first\",inplace=True)\n",
        "df_test.drop_duplicates(subset=['text'] , keep=\"first\",inplace=True)"
      ],
      "metadata": {
        "id": "DjKG1rucZDeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words =['من',\n",
        " 'في',\n",
        " 'على',\n",
        " 'و',\n",
        " 'فى',\n",
        " 'يا',\n",
        " 'عن',\n",
        " 'مع',\n",
        " 'ان',\n",
        " 'هو',\n",
        " 'علي',\n",
        " 'ما',\n",
        " 'اللي',\n",
        " 'كل',\n",
        " 'بعد',\n",
        " 'ده',\n",
        " 'اليوم',\n",
        " 'أن',\n",
        " 'يوم',\n",
        " 'انا',\n",
        " 'إلى',\n",
        " 'كان',\n",
        " 'ايه',\n",
        " 'اللى',\n",
        " 'الى',\n",
        " 'دي',\n",
        " 'بين',\n",
        " 'انت',\n",
        " 'أنا',\n",
        " 'حتى',\n",
        " 'لما',\n",
        " 'فيه',\n",
        " 'هذا',\n",
        " 'واحد',\n",
        " 'احنا',\n",
        " 'اي',\n",
        " 'كده',\n",
        " 'إن',\n",
        " 'او',\n",
        " 'أو',\n",
        " 'عليه',\n",
        " 'ف',\n",
        " 'دى',\n",
        " 'مين',\n",
        " 'الي',\n",
        " 'كانت',\n",
        " 'أمام',\n",
        " 'زي',\n",
        " 'يكون',\n",
        " 'خلال',\n",
        " 'ع',\n",
        " 'كنت',\n",
        " 'هي',\n",
        " 'فيها',\n",
        " 'عند',\n",
        " 'التي',\n",
        " 'الذي',\n",
        " 'قال',\n",
        " 'هذه',\n",
        " 'قد',\n",
        " 'انه',\n",
        " 'ريتويت',\n",
        " 'بعض',\n",
        " 'أول',\n",
        " 'ايه',\n",
        " 'الان',\n",
        " 'أي',\n",
        " 'منذ',\n",
        " 'عليها',\n",
        " 'له',\n",
        " 'ال',\n",
        " 'تم',\n",
        " 'ب',\n",
        " 'دة',\n",
        " 'عليك',\n",
        " 'اى',\n",
        " 'كلها',\n",
        " 'اللتى',\n",
        " 'هى',\n",
        " 'دا',\n",
        " 'انك',\n",
        " 'وهو',\n",
        " 'ومن',\n",
        " 'منك',\n",
        " 'نحن',\n",
        " 'زى',\n",
        " 'أنت',\n",
        " 'انهم',\n",
        " 'معانا',\n",
        " 'حتي',\n",
        " 'وانا',\n",
        " 'عنه',\n",
        " 'إلي',\n",
        " 'ونحن',\n",
        " 'وانت',\n",
        " 'منكم',\n",
        " 'وان',\n",
        " 'معاهم',\n",
        " 'معايا',\n",
        " 'وأنا',\n",
        " 'عنها',\n",
        " 'إنه',\n",
        " 'اني',\n",
        " 'معك',\n",
        " 'اننا',\n",
        " 'فيهم',\n",
        " 'د',\n",
        " 'انتا',\n",
        " 'عنك',\n",
        " 'وهى',\n",
        " 'معا',\n",
        " 'آن',\n",
        " \"لذلك\",\n",
        " 'انتي',\n",
        " 'وأنت',\n",
        " 'وإن',\n",
        " 'ومع',\n",
        " 'وعن',\n",
        " 'معاكم',\n",
        " 'معاكو',\n",
        " 'معاها',\n",
        " 'وعليه',\n",
        " 'وانتم',\n",
        " 'وانتي',\n",
        " '¿',\n",
        " '|']"
      ],
      "metadata": {
        "id": "BRtTqPRbZDgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punct_pattern = (\n",
        "    r\"([!\\\"#\\$%\\'\\(\\)\\*\\+,\\.:;\\-<&=·>?@\\[\\\\\\]\\^_ـ`{\\|}~—٪’،؟`୍“؛”ۚ【»؛\\s+«–…‘]{2,})\"\n",
        ")"
      ],
      "metadata": {
        "id": "jnopJlnwZDjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(sentence):\n",
        "    '''\n",
        "    Argument:\n",
        "        string of words\n",
        "    return:\n",
        "        string of words but standardize the words\n",
        "    '''\n",
        "    sentence = re.sub(\"[إأآا]\", \"ا\", sentence)\n",
        "    sentence = re.sub(\"ى\", \"ي\", sentence)\n",
        "    sentence = re.sub(\"ؤ\", \"ء\", sentence)\n",
        "    sentence = re.sub(\"ئ\", \"ء\", sentence)\n",
        "    sentence = re.sub(\"ة\", \"ه\", sentence)\n",
        "    sentence = re.sub(\"گ\", \"ك\", sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "5aIgTAhDZMdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removing_ar_stopwords(text):\n",
        "    \"\"\"\n",
        "        Here we remove all Arabic stop words\n",
        "        \n",
        "    \"\"\"\n",
        "    original_words = []\n",
        "    words = word_tokenize(text) \n",
        "    for word in words:\n",
        "        if word not in stop_words:\n",
        "            original_words.append(word)\n",
        "    filtered_sentence = \" \".join(original_words)\n",
        "    return filtered_sentence"
      ],
      "metadata": {
        "id": "QlQwCDO3ZMab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punkt_num(sentence):\n",
        "  '''\n",
        "    Argument:\n",
        "        string of words\n",
        "    return:\n",
        "        string of words but after removing punctuations and digits\n",
        "  '''\n",
        "  text = re.sub(punct_pattern,\"\",sentence)\n",
        "  text = re.sub(\"[0123456789]\",\"\",text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Iy3CrSvRZMX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "  '''\n",
        "    Argument:\n",
        "        string of words as a dataframe\n",
        "    return:\n",
        "        a cleaned dataframe after applying preprocessing\n",
        "  '''\n",
        "  cleared_tweet_1 = []       \n",
        "  cleared_tweet_1_2 = []         \n",
        "  cleared_tweet_1_2_3 = []       \n",
        "\n",
        "  data_text = data['text'].tolist()\n",
        "\n",
        "  for tweet in data_text: \n",
        "    cleared_tweet_1.append(removing_ar_stopwords(tweet))        \n",
        "\n",
        "  for tweets in cleared_tweet_1:\n",
        "    cleared_tweet_1_2.append(normalize(tweets))                \n",
        "                              \n",
        "  for tweetss in cleared_tweet_1_2:\n",
        "    cleared_tweet_1_2_3.append(remove_punkt_num(tweetss)) \n",
        "\n",
        "  data['text'] = cleared_tweet_1_2_3\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "FziK1CytZMVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_cleaned = preprocess(df_train)\n",
        "df_dev_cleaned = preprocess(df_dev)\n",
        "df_test_cleaned = preprocess(df_test)"
      ],
      "metadata": {
        "id": "cCMxoMv0ZMS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_cleaned.drop(columns=['Unnamed: 0'] , inplace=True)\n",
        "df_dev_cleaned.drop(columns=['Unnamed: 0'] , inplace=True)  \n",
        "df_train_cleaned.drop(columns=['Unnamed: 0'] , inplace=True) "
      ],
      "metadata": {
        "id": "HrbqbhwtZXyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Wz9xuK9ZdUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FdB53folZefl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-ao3cCj1Zeh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "owefsyzjZenK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}